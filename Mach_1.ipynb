{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class value:\n",
    "    def __init__(self, data, label = \"V\", backprop = lambda : None, grad = 0.0):\n",
    "        self.data, self.label, self.backprop, self.grad = data, label, backprop, grad\n",
    "    def __add__(self, other):\n",
    "        out =  value(self.data + other.data)\n",
    "        def backprop():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "            self.backprop()\n",
    "            other.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __mul__(self, other):\n",
    "        out =  value(self.data * other.data)\n",
    "        def backprop():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "            self.backprop()\n",
    "            other.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __radd__(self, other):\n",
    "        return self.__add__(value(other))\n",
    "    def __repr__(self):\n",
    "        return f\"{self.label} : {self.data}\"\n",
    "    def __pow__(self, power : int):\n",
    "        out = value(self.data ** power)\n",
    "        def backprop():\n",
    "            self.grad+= out.grad * (power * (self.data ** (power - 1)))\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __sub__(self, other):\n",
    "        return self + (value(-1) * other)\n",
    "    def __truediv__(self, other):\n",
    "        return self * (other ** -1)\n",
    "    def ReLU(self):\n",
    "        out = value(0 if self.data < 0 else self.data)\n",
    "        def backprop():\n",
    "            self.grad += out.grad * (0 if self.data < 0 else 1)\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        out = value(((math.exp(2 * self.data) - 1 + 1e-15) / (math.exp(2 * self.data) + 1) + 1e-15))\n",
    "        def backprop():\n",
    "            self.grad += out.grad * (1 - (out.data ** 2))\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "\n",
    "def Numerical2Value(numericalArr : list) -> list[value]:\n",
    "    return [value(numerical) for numerical in numericalArr]\n",
    "\n",
    "def mse(predictedVec : list[value], actualVec : list[value]) -> value:\n",
    "    simpleError = sum([(prediction - actual) ** 2 for prediction , actual in zip(predictedVec, actualVec)]) / value(len(actualVec))\n",
    "    return simpleError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "    def __init__(self, inputSize : int):\n",
    "        self.b = value(random.uniform(-1, 1))\n",
    "        self.w = [value(random.uniform(-1, 1)) for _ in range(inputSize)]\n",
    "    def __call__(self, inputs):\n",
    "        weightedSum = sum([xi * wi for xi, wi in zip(inputs, self.w)])\n",
    "        addedBias = self.b + weightedSum\n",
    "        activated = addedBias.tanh()\n",
    "        return activated\n",
    "    def getParams(self):\n",
    "        return [self.b] + self.w\n",
    "\n",
    "class layer:\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        self.neurons = [neuron(inputSize) for _ in range(outputSize)]\n",
    "    def __call__(self, inputs):\n",
    "        return [n(inputs) for n in self.neurons]\n",
    "    def getParams(self):\n",
    "        return [params for neuron in self.neurons for params in neuron.getParams()]\n",
    "\n",
    "class network:\n",
    "    def __init__(self, layerDims : list):\n",
    "        self.layers = []\n",
    "        for i in range(len(layerDims) - 1):\n",
    "            self.layers.append(layer(layerDims[i], layerDims[i + 1]))\n",
    "    def __call__(self, inputVec : value):\n",
    "        outputVec = inputVec\n",
    "        for layer in self.layers:\n",
    "            outputVec = layer(outputVec)\n",
    "        return outputVec\n",
    "    def getParams(self) -> list[value]:\n",
    "        return [params for layer in self.layers for params in layer.getParams()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(network, lr = 0.01):\n",
    "    for epochs in range(100):\n",
    "        pred, act = network(Numerical2Value([0.1, 0.2])), Numerical2Value([0.3])\n",
    "        loss = mse(pred, act)\n",
    "\n",
    "        def flushGradients():\n",
    "            for p in network.getParams():\n",
    "                p.grad = 0.0\n",
    "        \n",
    "        def backpropLoss():\n",
    "            loss.grad = 1.0\n",
    "            loss.backprop()\n",
    "        \n",
    "        def clipGrad():\n",
    "            for p in network.getParams():\n",
    "                if p.grad > 7:\n",
    "                    p.grad = 7\n",
    "                if p.grad < -7:\n",
    "                    p.grad = -7\n",
    "\n",
    "        def adjustParams():\n",
    "            for p in network.getParams():\n",
    "                p.data -= p.grad * lr\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        flushGradients()\n",
    "        backpropLoss()\n",
    "        clipGrad()\n",
    "        adjustParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = network([2, 4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pred : [V : -0.8795401713920303] actual : [V : 0.3] loss : V : 1.3913150159275405\n"
     ]
    }
   ],
   "source": [
    "#pre train prediction\n",
    "pred, act = n(Numerical2Value([0.1, 0.2])), Numerical2Value([0.3])\n",
    "loss = mse(pred, act)\n",
    "print(f\" pred : {pred} actual : {act} loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pred : [V : 0.2994223567136185] actual : [V : 0.3] loss : V : 3.3367176630160884e-07\n"
     ]
    }
   ],
   "source": [
    "#post train prediction\n",
    "pred, act = n(Numerical2Value([0.1, 0.2])), Numerical2Value([0.3])\n",
    "loss = mse(pred, act)\n",
    "print(f\" pred : {pred} actual : {act} loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
