{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class value:\n",
    "    def __init__(self, data, label = \"V\", backprop = lambda : None, grad = 0.0):\n",
    "        self.data, self.label, self.backprop, self.grad = data, label, backprop, grad\n",
    "    def __add__(self, other):\n",
    "        out =  value(self.data + other.data)\n",
    "        def backprop():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "            self.backprop()\n",
    "            other.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __mul__(self, other):\n",
    "        out =  value(self.data * other.data)\n",
    "        def backprop():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "            self.backprop()\n",
    "            other.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __radd__(self, other):\n",
    "        return self.__add__(value(other))\n",
    "    def __repr__(self):\n",
    "        return f\"{self.label} : {self.data}\"\n",
    "    def __pow__(self, power : int):\n",
    "        out = value(self.data ** power)\n",
    "        def backprop():\n",
    "            self.grad+= out.grad * (power * (self.data ** (power - 1)))\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __sub__(self, other):\n",
    "        return self + (value(-1) * other)\n",
    "    def __truediv__(self, other):\n",
    "        return self * (other ** -1)\n",
    "    def ReLU(self):\n",
    "        out = value(0 if self.data < 0 else self.data)\n",
    "        def backprop():\n",
    "            self.grad += out.grad * (0 if self.data < 0 else 1)\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "\n",
    "\n",
    "def Numerical2Value(numericalArr : list) -> list[value]:\n",
    "    return [value(numerical) for numerical in numericalArr]\n",
    "\n",
    "def mse(predictedVec : list[value], actualVec : list[value]) -> value:\n",
    "    simpleError = sum([(prediction - actual) ** 2 for prediction , actual in zip(predictedVec, actualVec)]) / value(len(actualVec))\n",
    "    return simpleError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "    def __init__(self, inputSize : int):\n",
    "        self.b = value(random.uniform(-1, 1))\n",
    "        self.w = [value(random.uniform(-1, 1)) for _ in range(inputSize)]\n",
    "    def __call__(self, inputs):\n",
    "        weightedSum = sum([xi * wi for xi, wi in zip(inputs, self.w)])\n",
    "        addedBias = self.b + weightedSum\n",
    "        activated = addedBias.ReLU()\n",
    "        return activated\n",
    "    def getParams(self):\n",
    "        return [self.b] + self.w\n",
    "\n",
    "class layer:\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        self.neurons = [neuron(inputSize) for _ in range(outputSize)]\n",
    "    def __call__(self, inputs):\n",
    "        return [n(inputs) for n in self.neurons]\n",
    "    def getParams(self):\n",
    "        return [params for neuron in self.neurons for params in neuron.getParams()]\n",
    "\n",
    "class network:\n",
    "    def __init__(self, layerDims : list):\n",
    "        self.layers = []\n",
    "        for i in range(len(layerDims) - 1):\n",
    "            self.layers.append(layer(layerDims[i], layerDims[i + 1]))\n",
    "    def __call__(self, inputVec : value):\n",
    "        outputVec = inputVec\n",
    "        for layer in self.layers:\n",
    "            outputVec = layer(outputVec)\n",
    "        return outputVec\n",
    "    def getParams(self) -> list[value]:\n",
    "        return [params for layer in self.layers for params in layer.getParams()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(network, loss):\n",
    "    loss.grad = 1.0\n",
    "    def backpropLoss():\n",
    "        loss.backprop()\n",
    "\n",
    "    def adjustParams(lr = 0.001):\n",
    "        for p in network.getParams():\n",
    "            p.data -= p.grad * lr\n",
    "\n",
    "    def flushGradients():\n",
    "        for p in network.getParams():\n",
    "            p.grad = 0.0\n",
    "    \n",
    "    flushGradients()\n",
    "    backpropLoss()\n",
    "    adjustParams()\n",
    "    \n",
    "\n",
    "n = network([2, 2, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
