{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [],
   "source": [
    "class value:\n",
    "    def __init__(self, data, label = \"V\", backprop = lambda : None, grad = 0.0):\n",
    "        self.data, self.label, self.backprop, self.grad = data, label, backprop, grad\n",
    "    def __add__(self, other):\n",
    "        out =  value(self.data + other.data)\n",
    "        def backprop():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "            self.backprop()\n",
    "            other.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __mul__(self, other):\n",
    "        out =  value(self.data * other.data)\n",
    "        def backprop():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "            self.backprop()\n",
    "            other.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __radd__(self, other):\n",
    "        return self.__add__(value(other))\n",
    "    def __repr__(self):\n",
    "        return f\"{self.label} : {self.data}\"\n",
    "    def __pow__(self, power : int):\n",
    "        out = value(self.data ** power)\n",
    "        def backprop():\n",
    "            self.grad+= out.grad * (power * (self.data ** (power - 1)))\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    def __sub__(self, other):\n",
    "        return self + (value(-1) * other)\n",
    "    def __truediv__(self, other):\n",
    "        return self * (other ** -1)\n",
    "    def ReLU(self):\n",
    "        out = value(0 if self.data < 0 else self.data)\n",
    "        def backprop():\n",
    "            self.grad += out.grad * (0 if self.data < 0 else 1)\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        out = value(((math.exp(2 * self.data) - 1 + 1e-15) / (math.exp(2 * self.data) + 1) + 1e-15))\n",
    "        def backprop():\n",
    "            self.grad += out.grad * (1 - (out.data ** 2))\n",
    "            self.backprop()\n",
    "        out.backprop = backprop\n",
    "        return out\n",
    "\n",
    "def Numerical2Value(numericalArr : list) -> list[value]:\n",
    "    return [value(numerical) for numerical in numericalArr]\n",
    "\n",
    "def NumArrs2ValArrs(ArrOfNum : list[list[float]]) -> list[list[value]]:\n",
    "    return [Numerical2Value(numArr) for numArr in ArrOfNum]\n",
    "\n",
    "def mse(predictedVec : list[value], actualVec : list[value]) -> value:\n",
    "    simpleError = sum([(prediction - actual) ** 2 for prediction , actual in zip(predictedVec, actualVec)]) / value(len(actualVec))\n",
    "    return simpleError\n",
    "\n",
    "def dataSetErrorEval(x, y, network):\n",
    "    p = [network(xi) for xi in x]\n",
    "    mae = 0\n",
    "    for act, pred in zip(y, p):\n",
    "        mae+=abs(act[0].data - pred[0].data)\n",
    "    return mae / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "    def __init__(self, inputSize : int):\n",
    "        self.b = value(random.uniform(-1, 1))\n",
    "        self.w = [value(random.uniform(-1, 1)) for _ in range(inputSize)]\n",
    "    def __call__(self, inputs):\n",
    "        weightedSum = sum([xi * wi for xi, wi in zip(inputs, self.w)])\n",
    "        addedBias = self.b + weightedSum\n",
    "        activated = addedBias.tanh()\n",
    "        return activated\n",
    "    def getParams(self):\n",
    "        return [self.b] + self.w\n",
    "\n",
    "class layer:\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        self.neurons = [neuron(inputSize) for _ in range(outputSize)]\n",
    "    def __call__(self, inputs):\n",
    "        return [n(inputs) for n in self.neurons]\n",
    "    def getParams(self):\n",
    "        return [params for neuron in self.neurons for params in neuron.getParams()]\n",
    "\n",
    "class network:\n",
    "    def __init__(self, layerDims : list):\n",
    "        self.layers = []\n",
    "        for i in range(len(layerDims) - 1):\n",
    "            self.layers.append(layer(layerDims[i], layerDims[i + 1]))\n",
    "    def __call__(self, inputVec : value):\n",
    "        outputVec = inputVec\n",
    "        for layer in self.layers:\n",
    "            outputVec = layer(outputVec)\n",
    "        return outputVec\n",
    "    def getParams(self) -> list[value]:\n",
    "        return [params for layer in self.layers for params in layer.getParams()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(network, xTrain, yTrain, lr = 0.01):\n",
    "    for epochs in range(10000):\n",
    "        for x, y in zip(xTrain, yTrain):\n",
    "            pred, act = network(x), y\n",
    "            loss = mse(pred, act)\n",
    "\n",
    "            def flushGradients():\n",
    "                for p in network.getParams():\n",
    "                    p.grad = 0.0\n",
    "            \n",
    "            def backpropLoss():\n",
    "                loss.grad = 1.0\n",
    "                loss.backprop()\n",
    "            \n",
    "            def clipGrad():\n",
    "                for p in network.getParams():\n",
    "                    if p.grad > 7:\n",
    "                        p.grad = 7\n",
    "                    if p.grad < -7:\n",
    "                        p.grad = -7\n",
    "\n",
    "            def adjustParams():\n",
    "                for p in network.getParams():\n",
    "                    p.data -= p.grad * lr\n",
    "            \n",
    "\n",
    "            flushGradients()\n",
    "            backpropLoss()\n",
    "            clipGrad()\n",
    "            adjustParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = network([2, 4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = NumArrs2ValArrs([\n",
    "    [0.1, 0.2],\n",
    "    [0.3, 0.4],\n",
    "    [0.5, 0.6],\n",
    "    [0.7, 0.8],\n",
    "    [0.9, 1.0],\n",
    "    [1.1, 1.2],\n",
    "    [1.3, 1.4],\n",
    "    [1.5, 1.6],\n",
    "    [1.7, 1.8],\n",
    "    [1.9, 2.0],\n",
    "    [2.1, 2.2],\n",
    "    [2.3, 2.4],\n",
    "    [2.5, 2.6],\n",
    "    [2.7, 2.8],\n",
    "    [2.9, 3.0]\n",
    "])\n",
    "\n",
    "yTrain = NumArrs2ValArrs([\n",
    "    [0.3],\n",
    "    [0.7],\n",
    "    [1.1],\n",
    "    [1.5],\n",
    "    [1.9],\n",
    "    [2.3],\n",
    "    [2.7],\n",
    "    [3.1],\n",
    "    [3.5],\n",
    "    [3.9],\n",
    "    [4.3],\n",
    "    [4.7],\n",
    "    [5.1],\n",
    "    [5.5],\n",
    "    [5.9]\n",
    "]\n",
    ")\n",
    "\n",
    "xTest = NumArrs2ValArrs([\n",
    "    [3.1, 3.2],\n",
    "    [3.3, 3.4],\n",
    "    [3.5, 3.6],\n",
    "    [3.7, 3.8],\n",
    "    [3.9, 4.0]\n",
    "])\n",
    "\n",
    "yTest = NumArrs2ValArrs([\n",
    "    [6.3],\n",
    "    [6.7],\n",
    "    [7.1],\n",
    "    [7.5],\n",
    "    [7.9]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error across Test data 7.335620678431866\n",
      "adding 0.2 and 0.5 [V : -0.6219934570003613]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average error across Test data\", dataSetErrorEval(xTest, yTest, n))\n",
    "print(\"adding 0.2 and 0.5\", n(Numerical2Value([0.2, 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(n, xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error across Test data 6.100007999432449\n",
      "adding 0.2 and 0.5 [V : 0.6321463183169777]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average error across Test data\", dataSetErrorEval(xTest, yTest, n))\n",
    "print(\"adding 0.2 and 0.5\", n(Numerical2Value([0.2, 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
